---
title: "Problem Set 4, Winter 2024"
author: "Michael Ghattas"
output: pdf_document
---

```{r setup, include=TRUE}
# Load necessary packages
library(ggplot2)
library(tidyverse)
library(GGally)
library(ggpubr)
library(leaps) 
library(tidyverse)
```

CONTEXT: Factorial experiment with doughnuts

Donna is the owner of a boutique doughnut shop. Because many of her customers are conscious of their fat intake but want the flavor of fried doughnuts, she decided to develop a doughnut recipe that minimizes the amount of fat that the doughnuts absorb from the fat in which the doughnuts are fried.

She conducted a factorial experiment that had a similar procedures as Lowe (1935). Like Lowe, she used four types of fats (fat_type). She also used three types of flour (flour_type): all-purpose flour, whole wheat flour, and gluten-free flour. For each combination of fat type and flour type, she cooked six identical batches of doughnuts. Each batch contained 24 doughnuts, and the total fat (in grams) absorbed by the doughnuts in each batch was recorded (sim_tot_fat).

## Question 1 - Nested model testing (15 points)

As previously noted, ANOVA is a special case of regression, so anything that can be done in the ANOVA framework can be done in the regression framework. However, this property often isn't obvious when comparing the output of equivalently-specified analyses. For example, the output of the two-way ANOVA with an interaction displays clearly labeled tests of two main effects and one test of the interaction, but the output of the equivalent regression model displays estimates of numerous coefficients that have interpretations different than those used in the ANOVA framework.

In this question, you will use nested model testing to conduct the equivalent tests of main effects and interactions using the regression framework.  

Before you start, read in the data and do your data processing.

```{r }
# Read in the doughnuts data
doughnuts.factorial <- read.csv("doughnutsfactorial.csv", header=TRUE, sep=",")
```

As in the previous problem set, please create two new variables in the doughnuts.factorial data set. The first new variable will be called fat_type_factor and will contain the same values as in the fat_type variable but will have a variable type of factor. The second new variable will be called flour_type_factor and will contain the same values as in the flour_type variable but will also have a variable type of factor. 

```{r}
# Create factor variables for fat_type and flour_type
doughnuts.factorial$fat_type_factor <- factor(doughnuts.factorial$fat_type)
doughnuts.factorial$flour_type_factor <- factor(doughnuts.factorial$flour_type)
```

Check your work by running the following code chunk. Be sure that fat_type_factor and flour_type_factor are factor-type variables before you complete the rest of the problem set.

```{r}
# Check the structure of the data
str(doughnuts.factorial)
```

# Question 1, Part 1 - Nested model testing of main effects (5 points)

For this part, you will start by fitting three regression models: an intercept-only model, a fat type-only model, and a flour-type only model. For all models, use sim_tot_fat as the outcome. 

Fit the intercept-only model here:
```{r}
# Fit the intercept-only model
model.null <- lm(sim_tot_fat ~ 1, data=doughnuts.factorial)
summary(model.null)
```

Fit the fat type-only model here:
```{r}
# Fit the fat type-only model
model.fatType <- lm(sim_tot_fat ~ fat_type_factor, data=doughnuts.factorial)
summary(model.fatType)
```

Fit the flour type-only model here:
```{r}
# Fit the flour type-only model
model.flourType <- lm(sim_tot_fat ~ flour_type_factor, data=doughnuts.factorial)
summary(model.flourType)
```

Now, conduct two nested model tests to conduct the ANOVA-equivalent tests of main effect. 

Conduct a nested model test between the intercept-only model and the fat type-only model:
```{r}
# Conduct a nested model test between intercept-only and fat type model
anova(model.null, model.fatType)
```

Conduct a nested model test between the intercept-only model and the flour type-only model:
```{r}
# Conduct a nested model test between intercept-only and flour type model
anova(model.null, model.flourType)
```

# Question 1, Part 2 - Nested model testing of interaction (5 points)

Unlike the previous part, the "base" model for this comparison is not an intercept-only model. Rather, the base model is a model where the interaction is omitted. In the regression framework, this means that the correct reduced model for this ANOVA-equivalent test is a model that includes fat type and flour type, but no interaction between them. 

Fit the reduced model, which will contain just fat type and flour type (no interaction), below
```{r}
# Fit the reduced model (fat type and flour type, no interaction)
model.main <- lm(sim_tot_fat ~ fat_type_factor + flour_type_factor, data=doughnuts.factorial)
summary(model.main)
```

Fit the full model, which will contain fat type, flour type, and their interaction
```{r}
# Fit the full model (fat type, flour type, and their interaction)
model.interaction <- lm(sim_tot_fat ~ fat_type_factor * flour_type_factor, data=doughnuts.factorial)
summary(model.interaction)
```

Now, conduct one nested model test to conduct the ANOVA-equivalent test of the interaction effect. 

```{r}
# Conduct a nested model test for interaction effect
anova(model.main, model.interaction)
```

# Question 1, Part 3 - Interpreting your results (5 points)

You will answer three questions comparing the results of your nested regression model tests and the ANOVA-style tests. 

Question A: Run the code chunk below to see the results of the one-way ANOVA for fat type you conducted in a previous problem set before answering the question.

```{r}
# One-way ANOVA for fat type
doughnuts.fat <- aov(sim_tot_fat ~ fat_type_factor, data=doughnuts.factorial)
summary(doughnuts.fat)
```

Look at the results of the nested model test you conducted comparing the intercept-only model with a model including just *fat type* in *Question 1, Part 1*. Does the F-change test statistic and p-value from that nested model test match the F statistic and p-value (within rounding) of the test in the one-way ANOVA?

Your answer here (yes/no): Yes, both tests provide an F-statistic of approximately 20.17 and a p-value of 1.856e-09.


Question B: Run the code chunk below to see the results of the one-way ANOVA for flour type you conducted in a previous problem set before answering the question.

```{r}
# One-way ANOVA for flour type
doughnuts.flour <- aov(sim_tot_fat ~ flour_type_factor, data=doughnuts.factorial)
summary(doughnuts.flour)
```

Look at the results of the nested model test you conducted comparing the intercept-only model with a model including just *flour type* in *Question 1, Part 1*. Does the F-change test statistic and p-value from that nested model test match the F statistic and p-value (within rounding) of the test in the one-way ANOVA?

Your answer here (yes/no): Yes, the F-statistic for both tests is approximately 2.669 with a p-value of 0.076.

Question C) Run the code chunk below to see the results of the two-way ANOVA with an interaction model you conducted in a previous problem set before answering the question.

```{r}
# Two-way ANOVA with interaction
doughnuts.fact.2aov <- aov(sim_tot_fat ~ fat_type_factor + flour_type_factor + fat_type_factor*flour_type_factor, data=doughnuts.factorial)
summary(doughnuts.fact.2aov)
```

Look at the results of the nested model test comparing a model with fat type and flour type with a model that additionally includes the interaction between fat type and flour type you conducted in *Question 1, Part 2*. Does the F-change test statistic and p-value from the nested model test match the F statistic and p-value (within rounding) of the interaction test in the two-way ANOVA with an interaction?

Your answer here (yes/no): Yes, both tests show an F-statistic of approximately 0.674 and a p-value of 0.671 for the interaction term.

-----

CONTEXT - FISHERMAN DATA (many thanks to Dr. Durso for obtaining this data set)

Data Source: N.B. Al-Majed and M.R. Preston (2000). "Factors Influencing the Total
Mercury and Methyl Mercury in the Hair of Fishermen in Kuwait," 
Environmental Pollution, Vol. 109, pp. 239-250.

   http://users.stat.ufl.edu/~winner/datasets.html, downloaded on 4/23/2019

Description: Factors related to mercury levels among fishermen and a control
group of non-fishermen.

Variables (names of variables in the data set)

Fisherman indicator ("fisherman"), categorical
   0 = No
   1 = Yes

Age in years ("age"), continuous

Residence Time in years ("restime"), continuous

Height in cm ("height"), continuous 

Weight in kg ("weight"), continuous

Fish meals per week ("fishmlwk"), continuous

Parts of fish consumed ("fishpart"), categorical
    0 = none 
    1 = muscle tissue only
    2 = muscle tissue and sometimes whole fish 
    3 = whole fish
              
Methyl Mercury in mg/g ("MeHg"), continuous

Total Mercury in mg/g  ("TotHg"), continuous



# Do this part before starting Questions 2-4!

Before moving on to conducting automated model selection, you'll need to do some data processing. First, set the variables you'll use to the proper data types by completing the lines in the code chunk below. The variables you will include as predictors in your automated model selection are fisherman, age, restime, height, weight, fishmlwk, and fishpart

```{r}
# Read the fisherman data
fish <- read.csv("fishermen_mercury.csv", header=TRUE, sep=",")

# Convert categorical variables to factors
fish$fisherman_factor <- factor(fish$fisherman)
fish$fishpart_factor <- factor(fish$fishpart)
```

Check your work by running the following code chunk. Be sure that age, restime, height, weight, and fishmlwk and  are either integer-type variables or numeric-type variables (R should type these two appropriately automatically) and that fisherman_factor and fishpart_factor are factor-type variables before you complete the rest of the problem set.

```{r}
# Check structure of the data
str(fish)
```

Next, transform the outcome variable, TotHg, by taking it's log (note: do not conduct a Box Cox transformation; just take the log of the outcome variable). Conducting such a transformation isn't a routine part of automated model selection, but it is an option for improving regression diagnostics and we'll use it for this particular problem.

```{r}
# Log transform the outcome variable (TotHg)
fish$logTotHg <- log(fish$TotHg)
```

Finally, to make some of the later data manipulation easier, the following code chunk creates a new data set that contains only the transformed outcome and the predictors that will be included in the automated model selection. The select() function as used below requires that you have either the dplyr package or the tidyverse packaged loaded into memory. The first argument identifies the data set (fish) from which variables will be obtained, and the remaining arguments are variables from the fish data set that you want to be copied into the new data set. 

```{r}
# Create a new dataset with only relevant predictors
fish.auto <- select(fish, fisherman_factor, fishpart_factor, age, restime, height, weight, fishmlwk, logTotHg)
```

Upon occasion, using the select() function will cause an error because there is also a base R function named select(). If you encounter an error and you believe that conflicting function names is the cause, R allows you to add the library name in front of the function to clarify the source of the function. For example: dpylr::select(fish, fisherman_factor, fishpart_factor, age, restime, height, weight, fishmlwk, logTotHg). If you encounter an error running the above code chunk, try adding dpylr:: in front of the select() function.

Have one last look at your data structure to check that everything is as expected:

```{r}
# Check the structure of the new dataset
str(fish.auto)
```

## Question 2 - Forward selection (10 points)

Use forward selection to find the best set of predictors in the fish.auto data set to predict the log of total mercury (logTotHg). Be sure to include fisherman+_factor, age, restime, height, weight, fishmlwk, and fishpart_factor in your pool of potential predictors. Do not include interaction terms or polynomial terms as part of your pool of potential predictors. 

Be sure to include trace=1 in your function.

```{r}
# Conduct forward selection
model.forward <- step(lm(logTotHg ~ 1, data=fish.auto), 
                      scope = ~ fisherman_factor + fishpart_factor + age + restime + height + weight + fishmlwk,
                      direction = "forward", trace = 1)
```

Display the model selected using forward selection by using the summary() function.

```{r}
# Display the selected model
summary(model.forward)
```

## Question 3 - Backward selection (10 points)

Use backward selection to find the best set of predictors in the fish.auto data set to predict the log of total mercury (logTotHg). Be sure to include fisherman+_factor, age, restime, height, weight, fishmlwk, and fishpart_factor in your pool of potential predictors. Do not include interaction terms or polynomial terms as part of your pool of potential predictors. 

Be sure to include trace=1 in your function.

```{r}
# Conduct backward selection
model.backward <- step(lm(logTotHg ~ ., data=fish.auto), 
                       direction = "backward", trace = 1)
```

Display the model selected using forward selection by using the summary() function.

```{r}
# Display the selected model
summary(model.backward)
```

## Question 4 - Best subsets selection (10 points)

Use best subsets selection to find the best set of predictors in the fish.auto data set to predict the log of total mercury (logTotHg). Be sure to include fisherman_factor, age, restime, height, weight, fishmlwk, and fishpart_factor in your pool of potential predictors. Do not include interaction terms or polynomial terms as part of your pool of potential predictors. 

For this problem, choose the best model based on BIC. 

```{r}
# Conduct the best subsets selection using BIC
best.subsets <- regsubsets(logTotHg ~ fisherman_factor + fishpart_factor + age + restime + height + weight + fishmlwk, 
                           data = fish.auto, nvmax = 7)

# Display the summary of the best subsets model selection
summary(best.subsets)

# Find the model that minimizes BIC
best_bic_model <- summary(best.subsets)$which[which.min(summary(best.subsets)$bic),]
print(best_bic_model)
```

Display the model selected using best subsets selection with BIC values. Note: you do not need to "scrape" from the results of using regsubsets() to earn full credit here - you just need to display the model selected using that process, which you can specify manually using the lm() function if you so choose; e.g., summary(lm(*your final model*)).

```{r}
# Final model based on best subsets selection (BIC)
best_bic_model <- lm(logTotHg ~ fishpart_factor + weight, data = fish.auto)
# Display the summary of the final model
summary(best_bic_model)
```

To compare the results of the best subsets selection with the results of forward and backward selection, you'll need to convert the model BIC values to AIC values. There is an example of how to do this in the async (3.3 Best Subsets Selection). 

```{r}
# Number of observations
n <- nrow(fish.auto)

# Number of predictors (including intercept)
k <- length(coef(best_bic_model))

# Extract BIC from the model
bic_value <- BIC(best_bic_model)

# Convert BIC to AIC
aic_value <- bic_value + k * log(n) - 2 * k

# Display the AIC value
aic_value
```

Once this is done, determine the best model using best subsets using the AIC values

```{r}
# List all possible models with different combinations of predictors
models <- list(
  lm(logTotHg ~ weight, data = fish.auto),
  lm(logTotHg ~ fishpart_factor, data = fish.auto),
  lm(logTotHg ~ weight + fishpart_factor, data = fish.auto),
  lm(logTotHg ~ fisherman_factor + weight, data = fish.auto),
  lm(logTotHg ~ fisherman_factor + fishpart_factor, data = fish.auto),
  lm(logTotHg ~ fisherman_factor + weight + fishpart_factor, data = fish.auto),
  lm(logTotHg ~ fisherman_factor + weight + fishpart_factor + fishmlwk, data = fish.auto)
)

# Extract AIC for each model
aic_values <- sapply(models, AIC)

# Identify the best model (one with the lowest AIC)
best_aic_index <- which.min(aic_values)
best_aic_model <- models[[best_aic_index]]
```

Display the model selected using best subsets selection with AIC values. Again, you don't have to "scrape" from the results of using regsubsets(). 

```{r}
# Display the summary of the best model based on AIC
summary(best_aic_model)
```

## Question 5 - 5 points

Question A: Which predictors were included in the model you chose using forward selection?

Your answer here: weight and fishpart_factor.

Question B: Which predictors were included in the model you chose using backward selection?

Your answer here: weight and fishpart_factor.

Question C: Which predictors were included in the model you chose using best subsets selection (AIC)?

Your answer here: weight and fishpart_factor.

Question D: Which predictors were included in the model you chose using best subsets selection (BIC)?

Your answer here: weight and fishpart_factor.


